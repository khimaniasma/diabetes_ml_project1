# -*- coding: utf-8 -*-
"""Copy of Logistical Regression for Diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BbAtRL5UTYcM4cMjr-YRChkqSLGs3G8Z
"""

# logistic_regression_optimized.py

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
from google.colab import drive

# Mount Google Drive
drive.mount("/content/drive", force_remount=True)

# File paths
data_file_path = "/content/drive/MyDrive/diabetes_Dataset_Team_ML.csv"
labels_file_path = "/content/drive/MyDrive/Diabetes_T1_labels.txt"

# Load the dataset and labels
def load_dataset(data_path, labels_path, usecols=None):
    """
    Load the feature dataset and labels in an optimized way.
    :param data_path: Path to the dataset CSV file.
    :param labels_path: Path to the labels TXT file.
    :param usecols: List of columns to load (optional).
    :return: Merged DataFrame with features and labels.
    """
    try:
        # Load features with selected columns (if specified)
        data = pd.read_csv(data_path, usecols=usecols, dtype='float32')
        labels = pd.read_csv(labels_path, delimiter='\t', usecols=[0], dtype='int8')  # Assuming labels in the first column

        # Merge labels into data
        data["label"] = labels.iloc[:, 0]
        print("Dataset and labels loaded successfully!")
        return data
    except Exception as e:
        print(f"Error loading dataset or labels: {e}")
        raise

# Preprocess the data
def preprocess_data(data, target_column):
    """
    Preprocess the dataset in a memory-efficient way.
    :param data: Pandas DataFrame.
    :param target_column: Name of the target column.
    :return: Feature matrix X and target vector y.
    """
    # Fill missing values
    if data.isnull().sum().any():
        print("Missing values found. Filling with mean.")
        data.fillna(data.mean(), inplace=True)

    # Separate features and target
    y = data[target_column]
    X = data.drop(target_column, axis=1)

    # Downcast features to save memory
    X = X.apply(pd.to_numeric, downcast='float')

    # Scale features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    print("Data preprocessing completed!")
    return X_scaled, y

# Train and evaluate the logistic regression model
def train_and_evaluate(X, y):
    """
    Train logistic regression model and evaluate its performance.
    :param X: Feature matrix.
    :param y: Target vector.
    :return: None
    """
    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train the model
    model = LogisticRegression()
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_test)
    y_pred_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class

    # Evaluate the model
    print("Model Accuracy:", accuracy_score(y_test, y_pred))
    print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred))

    # Calculate AUC
    auc_score = roc_auc_score(y_test, y_pred_prob)
    print("\nROC AUC Score:", auc_score)

    # Plot ROC Curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', label=f"ROC Curve (AUC = {auc_score:.2f})")
    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("Receiver Operating Characteristic (ROC) Curve")
    plt.legend()
    plt.show()

if __name__ == "__main__":
    # Target column name
   target_column = "label"

    # Specify columns to use (optional for memory optimization)
   selected_columns = None  # Set to a list of column names if known

    # Load, preprocess, and train
   data = load_dataset(data_file_path, labels_file_path, usecols=selected_columns)
   X, y = preprocess_data(data, target_column)
   train_and_evaluate(X, y)